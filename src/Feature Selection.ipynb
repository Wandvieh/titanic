{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Here, I want to apply what I learnt in [Introduction to Statistical Learning](https://www.statlearning.com/) Chapter 6 about Feature Selection. This also answers some of my questions in the Least Squares / Logistic Regression files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold)\n",
    "\n",
    "df = pd.read_csv(\"../train.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "for col in df.columns:\n",
    "    print(\"Missing rows in {0}:\".format(col), df[col].shape[0] - df[col].count())\n",
    "print(df.describe())\n",
    "\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I have to do some preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       int64\n",
      "Survived          int64\n",
      "Pclass            int64\n",
      "Name             object\n",
      "Sex            category\n",
      "Age             float64\n",
      "SibSp             int64\n",
      "Parch             int64\n",
      "Ticket           object\n",
      "Fare            float64\n",
      "Cabin            object\n",
      "Embarked       category\n",
      "SexNr              int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['SexNr'] = df['Sex'].cat.codes\n",
    "\n",
    "mean = np.mean(df['Age'])\n",
    "df['Age'] = df['Age'].fillna(mean)\n",
    "\n",
    "df['Embarked'] = df['Embarked'].astype('category')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Subset Selection\n",
    "\n",
    "1. Generate all best models with 0 to p predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl an Predictors: 0\n",
      "Beste Kombination: () mit R^2: 0\n",
      "Anzahl an Predictors: 1\n",
      "Beste Kombination: ('Embarked',) mit R^2: 0.2952307228626888\n",
      "Anzahl an Predictors: 2\n",
      "Beste Kombination: ('Fare', 'Embarked') mit R^2: 0.36768020891350406\n",
      "Anzahl an Predictors: 3\n",
      "Beste Kombination: ('Parch', 'Fare', 'Embarked') mit R^2: 0.38336856306416056\n",
      "Anzahl an Predictors: 4\n",
      "Beste Kombination: ('SibSp', 'Parch', 'Fare', 'Embarked') mit R^2: 0.39326065634846097\n",
      "Anzahl an Predictors: 5\n",
      "Beste Kombination: ('Age', 'SibSp', 'Parch', 'Fare', 'Embarked') mit R^2: 0.3974572876555986\n",
      "Anzahl an Predictors: 6\n",
      "Beste Kombination: ('SexNr', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked') mit R^2: 0.3978260472917734\n",
      "Anzahl an Predictors: 7\n",
      "Beste Kombination: ('Pclass', 'SexNr', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked') mit R^2: 0.39834629200884475\n"
     ]
    }
   ],
   "source": [
    "predictors = ['Pclass', 'SexNr', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "for p in range(0, len(predictors)+1):\n",
    "    print('Anzahl an Predictors:', p)\n",
    "    best_r2 = 0\n",
    "    best_predictors = ()\n",
    "    for combination in itertools.combinations(predictors, p):\n",
    "        X = MS(list(combination)).fit_transform(df)\n",
    "        results = sm.OLS(y,X, missing='drop').fit()\n",
    "        #print(summarize(results))\n",
    "        #print(\"Rsquared:\", results.rsquared)\n",
    "        if results.rsquared > best_r2:\n",
    "            best_r2 = results.rsquared\n",
    "            best_predictors = (combination)\n",
    "    print('Beste Kombination:', combination, 'mit R^2:', best_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for now, but 'Embarked' as a categorical value with 3 options is probably not implemented properly, since it only counts as one variable for my code, while it is implemented as two variables in the model. I will ignore that for now and see whether that is talked about later in the Book Chapter or in the Lab.\n",
    "\n",
    "Another problem with this is that the R^2 is measured on the training set instead of a test set, since I don't have a dedicated test set. Another problem is also that since the model all have different sizes, you actually can't really use R^2 (it will always be lower with more predictors). The solution for that is to use kfold CV as a measure. When having implemented that, I can properly rely on the model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               coef  std err       t  P>|t|\n",
      "intercept    1.3483    0.074  18.332  0.000\n",
      "Pclass      -0.1719    0.020  -8.508  0.000\n",
      "SexNr       -0.5044    0.028 -17.879  0.000\n",
      "Age         -0.0059    0.001  -5.457  0.000\n",
      "SibSp       -0.0412    0.013  -3.160  0.002\n",
      "Parch       -0.0160    0.018  -0.879  0.380\n",
      "Fare         0.0003    0.000   0.873  0.383\n",
      "Embarked[Q] -0.0025    0.055  -0.045  0.964\n",
      "Embarked[S] -0.0663    0.034  -1.931  0.054\n",
      "Rsquared: 0.39834629200884475\n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "# Implementing 10fold CV on one example\n",
    "\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "\n",
    "for id,item in enumerate (range(1,6)):\n",
    "    print(id,item)\n",
    "\n",
    "X = np.power.outer(H, np.arange(d+1))\n",
    "\n",
    "X = MS(list(combination)).fit_transform(df)\n",
    "results = sm.OLS(y,X, missing='drop').fit()\n",
    "print(summarize(results))\n",
    "print(\"Rsquared:\", results.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Stepwise Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
